{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb68f6a4-67c2-4f6b-bd90-4fc7e361fe86",
   "metadata": {},
   "source": [
    "![DLI Header](images/DLI_Header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e27fba5-6948-42c9-9ac3-bf8a67244619",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Iterative Prompt Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e13d039-9ec5-4617-912f-4bfc84f9324d",
   "metadata": {},
   "source": [
    "In this notebook we warm up by iterating on a set of simple prompts, familiarizing ourselves with the `transformers` pipeline and the LLaMA-2 model we will be using throughout the course.\n",
    "\n",
    "By iteratively experimenting with seemingly simple prompts, we will begin to see the importance of creating prompts that are **specific**, provide **cues** and will also learn about how to give the model **\"time to think\"** when given tasks that it might find challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db67bb-a953-4210-a032-bf9f7957ebad",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646c89b-a172-4773-8b93-1a213df8d746",
   "metadata": {},
   "source": [
    "By the time you complete this notebook you will be able to:\n",
    "- Use a `transformers` pipeline to generate responses from a LLaMA-2 LLM.\n",
    "- Craft prompts that are **specific**.\n",
    "- Craft prompts that give the model **\"time to think\"**.\n",
    "- Provide **cues** to the model to guide its response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c0fd90-b2c4-4432-a6f0-7d378325d0ed",
   "metadata": {},
   "source": [
    "## Video Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeab60a-a06a-43ff-8ddf-51d0d8f4a32f",
   "metadata": {},
   "source": [
    "Execute the cell below to load the video walkthrough of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5f1c59-ec1f-44c3-8628-41a240f610fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " from IPython.display import HTML\n",
    "\n",
    "video_url = \"https://d36m44n9vdbmda.cloudfront.net/assets/s-fx-12-v1/v2/02-prompting.mp4\"\n",
    "\n",
    "video_html = f\"\"\"\n",
    "<video controls width=\"640\" height=\"360\">\n",
    "    <source src=\"{video_url}\" type=\"video/mp4\">\n",
    "    Your browser does not support the video tag.\n",
    "</video>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(video_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e2324-6ed6-4658-910f-d15c68e26248",
   "metadata": {},
   "source": [
    "## Create LLaMA-2 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465f9aa8-b9d0-4c87-9b54-bcb9d59f9880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "model = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
    "\n",
    "llama_pipe = pipeline(\"text-generation\", model=model, device_map=\"auto\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc37a21-9dd5-46b0-a99a-243082a12981",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af26cb7-f326-4aec-91b8-128d87b8a7d3",
   "metadata": {},
   "source": [
    "In this notebook we will use the following function to support our interaction with the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b99117-4086-4737-ba05-f576ba8e9875",
   "metadata": {},
   "source": [
    "### Generate Model Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fca80c8-610c-4f46-bb11-65d1ad3dbc59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(prompt, max_length=1024, pipe=llama_pipe, **kwargs):\n",
    "    \"\"\"\n",
    "    Generates a response to the given prompt using a specified language model pipeline.\n",
    "\n",
    "    This function takes a prompt and passes it to a language model pipeline, such as LLaMA, \n",
    "    to generate a text response. The function is designed to allow customization of the \n",
    "    generation process through various parameters and keyword arguments.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt (str): The input text prompt to generate a response for.\n",
    "    - max_length (int): The maximum length of the generated response. Default is 1024 tokens.\n",
    "    - pipe (callable): The language model pipeline function used for generation. Default is llama_pipe.\n",
    "    - **kwargs: Additional keyword arguments that are passed to the pipeline function.\n",
    "\n",
    "    Returns:\n",
    "    - str: The generated text response from the model, trimmed of leading and trailing whitespace.\n",
    "\n",
    "    Example usage:\n",
    "    ```\n",
    "    prompt_text = \"Explain the theory of relativity.\"\n",
    "    response = generate(prompt_text, max_length=512, pipe=my_custom_pipeline, temperature=0.7)\n",
    "    print(response)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def_kwargs = dict(return_full_text=False, return_dict=False)\n",
    "    response = pipe(prompt.strip(), max_length=max_length, **kwargs, **def_kwargs)\n",
    "    return response[0]['generated_text'].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999e0dc-b67a-436d-a6df-ff86b8e5c0d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Capital of California"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf04e1-e084-4d05-a1a8-e51331f3c6eb",
   "metadata": {},
   "source": [
    "Let's begin with a very simple prompt, which we will pass to our `generate` function in order to get a response back from the LLaMA-2 model we are using. In this series of prompts we are interested for the model to respond to us with the capital of the state of California, which is *Sacramento*.\n",
    "\n",
    "Our hope for this experiment is to get back the exact response `\"Sacramento\"` without anything else in the repsonse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01702d62-b226-45b6-8e20-ed7f410b62e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': '\\n\\nAnswer: The capital of California is Sacramento.'}\n",
      "Answer: The capital of California is Sacramento.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the capital of California?\"\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c70c6-e7e8-46f0-8d28-5033460263a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbac8c9-319e-43f3-9859-b2f269bb50ff",
   "metadata": {},
   "source": [
    "The model did not understand that we only wanted the name of the capital city, without any other context, so let's craft a prompt that is more **specific**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a69727a1-e364-4a17-93d1-721be30b63e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': '\\n\\nAnswer: Sacramento'}\n",
      "Answer: Sacramento\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the capital of California? Only answer this question and do so in as few a words as possible.\"\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855424dc-6d97-41c4-8347-d98aba83a787",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de56c7ff-2627-4fca-9c97-4177340358c5",
   "metadata": {},
   "source": [
    "That is an improvement, but we are still getting a leading `Answer: ` in the response. Let's try to prevent this behavior by providing the model with the **cue** `Answer: `. Doing so may prevent the model from providing that text itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd4cbbf1-7b45-481f-8a2b-a4b6589aa800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': ' Sacramento.'}\n",
      "Sacramento.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the capital of California? Only answer this question and do so in as few a words as possible. Answer: \"\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27326d-a109-4483-a820-73cd66c63fbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vowels in Sacramento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeec1c9-d7bc-4a56-8938-8292f2b50331",
   "metadata": {},
   "source": [
    "In the following section we try to get the model to do something a little more complicated: tell us all the vowels in the name of the capital of California.\n",
    "\n",
    "The correct answer is S**a**cr**a**m**e**nt**o** -> **aaeo** -> **aeo**. It's worth noting that in order to make this easy on myself (and you) I performed multiple steps to arrive at my answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "546b97c2-b2a1-4251-adbc-864c271f2e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': '\\n\\nAnswer: The vowels in the capital of California are \"A\" and \"E\".'}\n",
      "Answer: The vowels in the capital of California are \"A\" and \"E\".\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Tell me the vowels in the capital of California.\"\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e13825-1418-432b-b5ea-167111451243",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf59eea-2643-43c8-be7f-7a1bb5f658a8",
   "metadata": {},
   "source": [
    "When models are faced with the need to reason in a way that requires multiple steps, it often helps to construct a prompt requesting that the model perform multiple intermediary steps, almost like asking it to show its work. This technique is often referred to as giving the model **\"time to think\"**.\n",
    "\n",
    "The prompt below aims for the same end result, but asks the model to take the intermediate step of responding with the capital of California, before then responding with the vowels in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91edcd68-c6ea-4dce-8f3a-1ae4a326ac56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': \"\\n\\nI'll start: the capital of California is Sacramento.\\n\\nNow, the vowels in Sacramento are a, e, and o.\"}\n",
      "I'll start: the capital of California is Sacramento.\n",
      "\n",
      "Now, the vowels in Sacramento are a, e, and o.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Tell me the capital of California, and then tell me all the vowels in it.\"\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8682e8d0-fb74-4b1e-8046-7b1037e83cb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33833fe-bd3f-482f-a4d8-068b65ec4639",
   "metadata": {},
   "source": [
    "Now that we see the effectiveness of giving the model **\"time to think\"**, let's try again with a slightly more complicated task: the vowels in the capital of California in reverse alphabetical order.\n",
    "\n",
    "The correct answer is S**a**cr**a**m**e**nt**o** -> **aaeo** -> **aeo** -> **oea**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd3413ea-8224-4a30-8ab5-b89f31f7f254",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': \"\\n\\nI'm thinking... uh... oh, I know this one! The vowels in the capital of California in reverse alphabetical order are... e-a-o-u!\"}\n",
      "I'm thinking... uh... oh, I know this one! The vowels in the capital of California in reverse alphabetical order are... e-a-o-u!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Tell me the vowels in the capital of California in reverse alphabetical order?\"\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e66050-4449-4c32-8bfa-ed0fa015c776",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7acd4f-1c53-47b5-961f-3f5fbf62311a",
   "metadata": {},
   "source": [
    "In order to assist the model, let's again give it **\"time to think\"** by prompting it to break down the task into intermediate steps and show its work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62f3756b-b976-43fb-b082-334bdecbadfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': \"\\n\\nI'm not sure if you're aware, but the capital of California is Sacramento.\\n\\nNow, let's get to the vowels. The vowels in Sacramento are A, E, and O.\\n\\nNow, let's put them in reverse alphabetical order. The reverse alphabetical order of the vowels in Sacramento is O, E, and A.\"}\n",
      "I'm not sure if you're aware, but the capital of California is Sacramento.\n",
      "\n",
      "Now, let's get to the vowels. The vowels in Sacramento are A, E, and O.\n",
      "\n",
      "Now, let's put them in reverse alphabetical order. The reverse alphabetical order of the vowels in Sacramento is O, E, and A.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Tell me the capital of California, and then tell me all the vowels in it, then tell me the vowels in reverse-alphabetical order.\"\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e501e-75d9-46e0-8fef-84a9cfd33166",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb4e198-d274-43cd-ba2c-620b8fbdd45b",
   "metadata": {},
   "source": [
    "While LLMs aren't necessarily the best tool for performing math, as an exercise, generate a response from the prompt below, which intends to get the product of multiplying 23 and 34, and then iteratively develop a prompt which results in your getting the correct answer. Be sure to consider how you can be **precise** in your prompt, and also, provide an opportunity for the model to have **\"time to think\"**.\n",
    "\n",
    "If you get stuck, a solution is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14541792-ee4e-44e9-8d13-a99c3a8d8d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23*34 # Show the actual answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24769517-7106-44dd-9e9b-a286a5f15483",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': ' cm.\\n\\n### Versions\\n\\nThere are several versions of the painting, including:\\n\\n1. The original version, which is considered the most authentic and is housed in the Louvre Museum in Paris.\\n2. A version from the early 16th century, which is housed in the National Gallery in London.\\n3. A version from the late 16th century, which is housed in the Prado Museum in Madrid.\\n4. A version from the 17th century, which is housed in the Hermitage Museum in St. Petersburg.\\n\\nEach version has its own unique characteristics and details, but they all share the same overall composition and theme.\\n\\n### Symbolism\\n\\nThe painting is rich in symbolism, with many objects and figures representing different aspects of life and death. Some of the most notable symbols include:\\n\\n1. The Fates: The three women in the painting, who represent the Fates, or the goddesses of destiny. They are depicted as spinning the thread of life, which represents the cycle of life and death.\\n2. The Angel: The angel in the painting, who is depicted as a messenger of God, represents the divine intervention that can save souls from damnation.\\n3. The Skull: The skull in the foreground of the painting represents the transience of human life and the inevitability of death.\\n4. The Flowers: The flowers in the painting, particularly the roses, represent the beauty and fragility of life.\\n5. The Tree: The tree in the background of the painting represents the tree of life, which is a symbol of eternal life and rebirth.\\n\\nOverall, the painting is a powerful representation of the human condition, and the struggle between life and death. It is a reminder of the fragility of human life and the importance of living a virtuous life to avoid damnation.'}\n",
      "cm.\n",
      "\n",
      "### Versions\n",
      "\n",
      "There are several versions of the painting, including:\n",
      "\n",
      "1. The original version, which is considered the most authentic and is housed in the Louvre Museum in Paris.\n",
      "2. A version from the early 16th century, which is housed in the National Gallery in London.\n",
      "3. A version from the late 16th century, which is housed in the Prado Museum in Madrid.\n",
      "4. A version from the 17th century, which is housed in the Hermitage Museum in St. Petersburg.\n",
      "\n",
      "Each version has its own unique characteristics and details, but they all share the same overall composition and theme.\n",
      "\n",
      "### Symbolism\n",
      "\n",
      "The painting is rich in symbolism, with many objects and figures representing different aspects of life and death. Some of the most notable symbols include:\n",
      "\n",
      "1. The Fates: The three women in the painting, who represent the Fates, or the goddesses of destiny. They are depicted as spinning the thread of life, which represents the cycle of life and death.\n",
      "2. The Angel: The angel in the painting, who is depicted as a messenger of God, represents the divine intervention that can save souls from damnation.\n",
      "3. The Skull: The skull in the foreground of the painting represents the transience of human life and the inevitability of death.\n",
      "4. The Flowers: The flowers in the painting, particularly the roses, represent the beauty and fragility of life.\n",
      "5. The Tree: The tree in the background of the painting represents the tree of life, which is a symbol of eternal life and rebirth.\n",
      "\n",
      "Overall, the painting is a powerful representation of the human condition, and the struggle between life and death. It is a reminder of the fragility of human life and the importance of living a virtuous life to avoid damnation.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"23x34\" # While you and I understand the intention of this prompt, to the model it is not at all **precise**\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897ea6f6-1259-4b1f-977c-e26cc2bdb489",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3a7ab61-dc0e-4ec2-b79d-7f7cc843dd63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': '\\n\\n23 x 34 = 762'}\n",
      "23 x 34 = 762\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the product of 23 and 34?\"\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c1181a-21c7-41bd-acbd-817aa20ae510",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3531114a-2570-4707-9afb-0d999841c2ee",
   "metadata": {},
   "source": [
    "Click on the `...` to see a working solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02322095-a320-4a0a-81b7-b3a62bc6ff18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': '\\n\\n23 x 34 = 23 x (30 + 4)\\n\\n= 23 x 30 + 23 x 4\\n\\n= 690 + 92\\n\\n= 782\\n\\nTherefore, 23 x 34 = 782.'}\n",
      "23 x 34 = 23 x (30 + 4)\n",
      "\n",
      "= 23 x 30 + 23 x 4\n",
      "\n",
      "= 690 + 92\n",
      "\n",
      "= 782\n",
      "\n",
      "Therefore, 23 x 34 = 782.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Calculate the product of 23 and 34. Use the steps typical of long multiplication and show your work.\"\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9253ae-933e-4bd0-8227-466b55526928",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Key Concept Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1408fc-a6bf-458d-a532-9635677300b9",
   "metadata": {},
   "source": [
    "The following key concepts were introduced in this notebook:\n",
    "\n",
    "- **Precise**: Being as explicit as necessary to guide the response of an LLM.\n",
    "- **Cue**: A conclusion to a prompt that guides its response, often to prevent it from including the cue itself in its response.\n",
    "- **\"Time to think\"**: A quality in prompts that supports LLM responses (often requiring calculation) by asking for the model to take multiple steps and show its work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e05bfc-8d95-4f64-8aca-32a9d5322bfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Restart the Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726c6cc-27e7-4f70-98a0-8bee153d1b38",
   "metadata": {},
   "source": [
    "In order to free up GPU memory for the next notebook, please run the following cell to restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f288ecb-54dc-4f4e-8cc9-54230e5f5ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "get_ipython().kernel.do_shutdown(restart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873337fb-d71e-4a08-9426-ced44978af4b",
   "metadata": {},
   "source": [
    "![DLI Header](images/DLI_Header.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
